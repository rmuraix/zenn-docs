---
title: "MMAction2でRawFrameDatasetを扱う"
emoji: "🕺"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["機械学習", "mmaction2", "初心者"]
published: true
---

## はじめに

[MMAction2](https://github.com/open-mmlab/mmaction2)の行動認識モデルでは、`RawFrameDataset` と`VideoDataset` が使用できます。
今回は、3DCNNモデルである**I3D**のコンフィグファイルを`VideoDataset`から`RawFrameDataset` に書き換えることを通して、`RawFrameDataset` の使い方を確認します。
コンフィグファイルは以下から確認できます。
https://github.com/open-mmlab/mmaction2/blob/465d7debd3ff6b1e59ae9602fd186dc2297702b3/configs/recognition/i3d/i3d_imagenet-pretrained-r50_8xb8-32x2x1-100e_kinetics400-rgb.py

なお、正確性には十分気をつけていますが、筆者はプロフェッショナルではないので間違いを含んでいる可能性があることをご了承ください。

## `VideoDataset`と`RawFrameDataset`の違い

MMAction2の行動認識モデルでは、データを以下の2つの形式で使用できます。

- `VideoDataset`: 動画ファイルとしてデータを用意
- `RawFrameDataset`: 各動画をフレームごとに分割し、連番画像として用意

## データセットの用意

### 動画データ

MMAction2のドキュメントによると、連番画像ファイルは以下のように配置する必要があります。ディレクトリ名は任意で構いませんが、画像のファイル名はデフォルトでは`img_00001.jpg`の形式です。

```
.
├── video1
│   ├── img_00001.jpg
│   ├── img_00002.jpg
│   ├── img_00003.jpg
│   └── ...
├── video2
│   ├── img_00001.jpg
│   ├── img_00002.jpg
│   ├── img_00003.jpg
│   └── ...
├── video3
│   ├── img_00001.jpg
│   ├── img_00002.jpg
│   ├── img_00003.jpg
│   └── ...
└── ...

```

次に、コンフィグファイルを以下のように書き換えます。

```diff python
- dataset_type = 'VideoDataset'
- data_root = 'data/kinetics400/videos_train'
- data_root_val = 'data/kinetics400/videos_val'
+ dataset_type = 'RawframeDataset'
+ data_root = 'path/to/your/data'
+ data_root_val = 'path/to/your/data'
```

:::message

`dataset_type`はRaw**f**rameDatasetとしなければなりません。
下記のデータセットタイプの説明ではRaw**F**rameDatasetと書かれているので、惑わされないようにしてください。

:::

https://mmaction2.readthedocs.io/en/latest/user_guides/prepare_dataset.html#action-recognition

### アノテーションファイル

`Train`/`Val`/`Test`用のラベル情報は、それぞれ`ann_file_train`、`ann_file_val`、`ann_file_test`変数に指定します。
これらのファイルの内容は、`<パス> <合計フレーム数> <クラス>`の形式で記述してください。パスは`data_root`または`data_root_val`からのパスを指定してください。

```
some/video1 163 1
some/video2 122 1
some/video3 258 2
some/video4 234 2
some/video5 295 3
some/video6 121 3
```

次に、コンフィグファイルのアノテーションファイルを更新します。ファイル名は任意の名前で構いません。

```diff python
- ann_file_train = 'data/kinetics400/kinetics400_train_list_videos.txt'
- ann_file_val = 'data/kinetics400/kinetics400_val_list_videos.txt'
- ann_file_test = 'data/kinetics400/kinetics400_val_list_videos.txt'
+ ann_file_train = 'path/to/your/ann_train.txt'
+ ann_file_val = 'path/to/your/ann_val.txt'
+ ann_file_test = 'path/to/your/ann_test.txt'
```

## pipelineの変更

データ拡張などを定義している`train_pipeline`/`val_pipeline`/`test_pipeline`を変更します。
`VideoDataset`用の`DecordInit`と`DecordDecode`は不要です。`DecordInit`は削除し、`DecordDecode`は`RawFrameDecode`に置き換えます。

```diff python
train_pipeline = [
-   dict(type='DecordInit', **file_client_args),
    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),
-   dict(type='DecordDecode'),
+   dict(type="RawFrameDecode"),
    dict(type='Resize', scale=(-1, 256)),
    dict(
        type='MultiScaleCrop',
        input_size=224,
        scales=(1, 0.8),
        random_crop=False,
        max_wh_scale_gap=0),
    dict(type='Resize', scale=(224, 224), keep_ratio=False),
    dict(type='Flip', flip_ratio=0.5),
    dict(type='FormatShape', input_format='NCTHW'),
    dict(type='PackActionInputs')
]
# val_pipelineとtest_pipelineも同様に
```

## dataloaderの変更

`train_dataloader`/`val_dataloader`/`test_dataloader`における、`dataset`内の`data_prefix`を以下のように変更します。

```diff python
train_dataloader = dict(
    batch_size=8,
    num_workers=8,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_train,
-       data_prefix=dict(video=data_root),
+       data_prefix=dict(img=data_root),
        pipeline=train_pipeline))
# val_pipelineとtest_pipelineもvideoをimgに変更する
```

これを変更しないと、`KeyError: 'img'`エラーが発生します。

## その他の変更

`RawFrameDataset`に限った話ではありませんが、データセットが変わっているのでクラス数なども変更しなければなりません。
クラス数は、`configs/_base_/models/i3d_r50.py`で定義されているので、コンフィグファイル内で上書きします。

```diff python
+ model = dict(
+   type="Recognizer3D",
+   backbone=dict(
+        type="ResNet3d",
+        pretrained2d=True,
+        pretrained="torchvision://resnet50",
+        depth=50,
+        conv1_kernel=(5, 7, 7),
+        conv1_stride_t=2,
+        pool1_stride_t=2,
+        conv_cfg=dict(type="Conv3d"),
+        norm_eval=False,
+        inflate=((1, 1, 1), (1, 0, 1, 0), (1, 0, 1, 0, 1, 0), (0, 1, 0)),
+        zero_init_residual=False,
+    ),
+    cls_head=dict(
+        type="I3DHead",
+        num_classes=400, #ここを変更
+        in_channels=2048,
+        spatial_type="avg",
+        dropout_ratio=0.5,
+        init_std=0.01,
+        average_clips="prob",
+    ),
+    data_preprocessor=dict(
+        type="ActionDataPreprocessor",
+        mean=[123.675, 116.28, 103.53],
+        std=[58.395, 57.12, 57.375],
+        format_shape="NCTHW",
+    ),
+)
```

その他の設定（学習済みモデルのロードやバッチサイズなど）も、環境や目的に応じて適宜変更してください。

## 最後に

今回は、MMAction2のI3Dモデルにおいて`VideoDataset`から`RawFrameDataset`へとコンフィグファイルを変更する手順を紹介しました。
本記事を通じて、設定の違いや各パラメータの変更方法に関する理解が深まり、今後のモデル実装やデータセット設定に役立てられることを願っています。
誤りや改善点があれば、お気軽にコメントいただけると嬉しいです。

## 参考

https://mmaction2.readthedocs.io/en/latest/user_guides/config.html
https://github.com/open-mmlab/mmaction2/issues/2713
